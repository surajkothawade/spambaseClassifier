{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spambase Classifier\n",
    "Spambase dataset is available from the UCI Machine Learning Repository:\n",
    "http://archive.ics.uci.edu/ml/datasets/Spambase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K fold Cross validation for fold:  1\n",
      "TRAIN: [   0    1    3 ... 4596 4598 4599] TEST: [   2    6   18 ... 4589 4594 4597]\n",
      "K fold Cross validation for fold:  2\n",
      "TRAIN: [   0    1    2 ... 4596 4597 4598] TEST: [   3    8   11 ... 4590 4591 4599]\n",
      "K fold Cross validation for fold:  3\n",
      "TRAIN: [   2    3    6 ... 4596 4597 4599] TEST: [   0    1    4 ... 4584 4595 4598]\n",
      "K fold Cross validation for fold:  4\n",
      "TRAIN: [   0    1    2 ... 4597 4598 4599] TEST: [  10   12   17 ... 4592 4593 4596]\n",
      "+----+---------------+------------+-------------------+-------------------+------------------+------------------+\n",
      "|    |   Accuracy(%) |   Error(%) |   False negatives |   False positives |   True negatives |   True positives |\n",
      "|----+---------------+------------+-------------------+-------------------+------------------+------------------|\n",
      "|  0 |       90.6957 |    9.30435 |                56 |                51 |              656 |              387 |\n",
      "|  1 |       88.8696 |   11.1304  |                73 |                55 |              627 |              395 |\n",
      "|  2 |       90.9565 |    9.04348 |                51 |                53 |              658 |              388 |\n",
      "|  3 |       89.8261 |   10.1739  |                82 |                35 |              653 |              380 |\n",
      "+----+---------------+------------+-------------------+-------------------+------------------+------------------+\n",
      "Average accuracy:  0.9008695652173913\n",
      "Average Error: 0.09913043478260869\n"
     ]
    }
   ],
   "source": [
    "#Read data from a csv to a dataframe\n",
    "df = pd.read_csv(\"data/spambase.data\")\n",
    "data = df.values.tolist()\n",
    "#Split the data into features and labels\n",
    "X = np.array([x[:-1] for x in data]).astype(np.float)\n",
    "#The last column hahs the labels\n",
    "y = np.array([x[-1] for x in data]).astype(np.float)\n",
    "#Split the data into k folds(4 in this case)\n",
    "#It is really important to shuffle the data :p\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "fold = 0\n",
    "# Choice of classifier (See the next cell)\n",
    "# clf = GaussianNB()\n",
    "# clf = SVC(gamma='auto')\n",
    "clf = BernoulliNB(alpha=1.0, binarize=0.25)\n",
    "foldScores = []\n",
    "acc = []\n",
    "err = []\n",
    "# Train and validate a classifier for each of the k folds\n",
    "for train_index, test_index in kf.split(X):\n",
    "    fold+=1\n",
    "    print(\"K fold Cross validation for fold: \", fold)\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "#     print(\"Number of training examples: \", len(X_train))\n",
    "#     print(\"Number of testing examples: \", len(X_test))\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "#     print(\"True positives: \", tp)\n",
    "#     print(\"False positives: \", fp)\n",
    "#     print(\"True negatives: \", tn)\n",
    "#     print(\"False negatives: \", fn)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    acc.append(score)\n",
    "    error = 1 - score\n",
    "    err.append(error)\n",
    "#     print(\"Accuracy (%): \", score*100) # (true_positive + true_negatives) / total_examples\n",
    "    foldScores.append({\"True positives\":tp, \"False positives\":fp, \"True negatives\":tn, \n",
    "                       \"False negatives\":fn, \"Accuracy(%)\": score*100, \"Error(%)\": error*100})\n",
    "results = pd.DataFrame(foldScores)\n",
    "print(tabulate(results,headers='keys', tablefmt='psql'))\n",
    "print(\"Average accuracy: \", np.mean(acc))\n",
    "print(\"Average Error:\", np.mean(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "# Choice of classifier\n",
    "Various research papers show the comparison of using Naive Bayes models for such tasks.\n",
    "Metsis et al. \"Spam Filtering with Naive Bayes â€“ Which Naive Bayes? compare multiple Naive Bayes models\n",
    "for spambase filtering and demonstrate that the binary multinomial model yields better results \n",
    "than the Bernoulli model. However, Bernoulli seems to work atleast at par.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
